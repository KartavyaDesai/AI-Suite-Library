{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AISuite Library\n",
    "## Using AISuite Library to effortlessly use models from multiple providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aisuite as ai\n",
    "import fitz\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['GROQ_API_KEY']=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ['HF_TOKEN']=os.getenv(\"HF_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeer∗\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Parmar∗\n",
      "Google Research\n",
      "nikip@google.com\n",
      "Jakob Uszkoreit∗\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jones∗\n",
      "Google Research\n",
      "llion@google.com\n",
      "Aidan N. Gomez∗†\n",
      "University of Toronto\n",
      "aidan@cs.toronto.edu\n",
      "Łukasz Kaiser∗\n",
      "Google Brain\n",
      "lukaszkaiser@google.com\n",
      "Illia Polosukhin∗‡\n",
      "illia.polosukhin@gmail.com\n",
      "Abstract\n",
      "The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks that include an encoder and a decoder. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer,\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "entirely. Exper\n"
     ]
    }
   ],
   "source": [
    "# Path to your PDF\n",
    "temp_pdf = \"./aian.pdf\"  # Replace with the actual path to your PDF file\n",
    "\n",
    "# Initialize an empty string to store the extracted text\n",
    "pdf_text = \"\"\n",
    "\n",
    "# Open the PDF file using PyMuPDF\n",
    "with fitz.open(temp_pdf) as doc:\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)  # Load each page\n",
    "        page_text = page.get_text(\"text\")  # Extract text from the page\n",
    "        \n",
    "        # Append the text from the page to pdf_text with a separator between pages\n",
    "        pdf_text += page_text.strip()  # Strip any leading/trailing spaces\n",
    "        if page_num < doc.page_count - 1:  # Avoid adding a separator after the last page\n",
    "            pdf_text += \"\\n--- PAGE BREAK ---\\n\"  # Separator for new page\n",
    "\n",
    "# Print the extracted text (for verification)\n",
    "print(pdf_text[:1000])  # Displaying first 1000 characters for inspection\n",
    "\n",
    "# The pdf_text variable now contains the full text of the PDF with page separators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Explain encoder and decoder in concise.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ai.Client()\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Answer the question only based on the below text.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Answer the question based on the following text:\\n\\n{pdf_text[:6000]}\\n\\nQuestion: {question}\\n\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder: Takes an input sequence and generates a sequence of hidden states, representing the input information.\n",
      "\n",
      "Decoder: Takes the hidden states generated by the encoder and produces an output sequence, synthesizing the input information.\n"
     ]
    }
   ],
   "source": [
    "provider = \"groq\"\n",
    "model_id = \"llama-3.2-3b-preview\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=f\"{provider}:{model_id}\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text does not provide a direct explanation of encoders and decoders in concise terms, but it is implied that they are key components in sequence transduction models, often used in conjunction with attention mechanisms.\n",
      "The encoder is responsible for processing the input sequence to produce a context or representation, typically in the form of hidden states. The decoder, on the other hand, generates the output sequence based on the context provided by the encoder. In many models, the\n"
     ]
    }
   ],
   "source": [
    "provider = \"huggingface\"\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=f\"{provider}:{model_id}\", \n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - By Kartavya Desai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
